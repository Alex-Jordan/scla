<?xml version="1.0" encoding="UTF-8" ?>
<section acro="IS">
<title>Invariant Subspaces</title>

<introduction></introduction>
<subsection>
<!-- %%%%%%%%%% -->
<!-- % -->
<!-- %  Section IS -->
<!-- %  Invariant Subspaces -->
<!-- % -->
<!-- %%%%%%%%%% -->
{\sc\large This section is in draft form}\\
{\sc\large Nearly complete}
<p><p>\medskip
We have seen in <acroref type="section" acro="NLT" /> that nilpotent linear transformations are almost never diagonalizable (<acroref type="theorem" acro="DNLT" />), yet have matrix representations that are very nearly diagonal (<acroref type="theorem" acro="CFNLT" />).  Our goal in this section, and the next (<acroref type="section" acro="JCF" />), is to obtain a matrix representation of <em>any</em> linear transformation that is very nearly diagonal.  A key step in reaching this goal is an understanding of invariant subspaces, and a particular type of invariant subspace that contains vectors known as <q>generalized eigenvectors.</q>
\subsect{IS}{Invariant Subspaces}

<example acro="ISJB" index="invariant subspace!Jordan block">
<title>Invariant subspaces and Jordan blocks</title>

Refer back to <acroref type="example" acro="CFNLT" />.  We decomposed the vector space $\complex{6}
<m> into a direct sum of the subspaces </m>Z_1,\,Z_2,\,Z_3,\,Z_4<m>.  The union of the basis vectors for these subspaces is a basis of </m>\complex{6}<m>, which we reordered prior to building a matrix representation of the linear transformation </m>T$.  A principal reason for this reordering was to create invariant subspaces (though it was not obvious then).<p><p>
Define
<me><md>
<mrow>
X_1
</mrow>
<mrow>&amp;=\spn{\set{\vect{z}_{1,1},\,\vect{z}_{2,1},\,\vect{z}_{3,1},\,\vect{z}_{4,1}}}]]>
=\spn{\set{
\colvector{1\\1\\0\\1\\1\\1},\,
\colvector{1\\0\\3\\1\\0\\-1},\,
\colvector{-3\\-3\\-3\\-3\\-3\\-2},\,
\colvector{1\\0\\0\\0\\0\\0}
}}\\
X_2
</mrow>
<mrow>&amp;=\spn{\set{\vect{z}_{1,2},\,\vect{z}_{2,2}}}]]>
=\spn{\set{\colvector{-2\\-2\\-5\\-2\\-1\\0},\,\colvector{2\\1\\2\\2\\2\\1}}}
</mrow>
</md></me>
Recall from the proof of <acroref type="theorem" acro="CFNLT" /> or the computations in <acroref type="example" acro="CFNLT" /> that first elements of <m>X_1</m> and <m>X_2</m> are in the kernel of <m>T</m>, <m>\krn{T}</m>, and each element of <m>X_1</m> and <m>X_2</m> is the output of <m>T</m> when evaluated with the subsequent element of the set.  This was by design, and it is this feature of these basis vectors that leads to the nearly diagonal matrix representation with Jordan blocks.  However, we also recognize now that this property of these basis vectors allow us to conclude easily that <m>X_1</m> and <m>X_2</m> are invariant subspaces of <m>\complex{6}</m> relative to <m>T</m>.<p><p>
Furthermore, <m>\complex{6}=X_1\ds X_2</m> (<acroref type="theorem" acro="DSFB" />).  So the domain of <m>T</m> is the direct sum of invariant subspaces and the resulting matrix representation has a block diagonal form.  Hmmmmm.
</example>



\subsect{RLT}{Restrictions of Linear Transformations}
Generalized eigenspaces will prove to be an important type of invariant subspace.  



Suppose that <m>\ltdefn{T}{V}{V}</m> is a linear transformation and we can find a decomposition of <m>V</m> as a direct sum, say <m>V=U_1\ds U_2\ds U_3\ds\cdots\ds U_m</m> where each <m>U_i</m> is an invariant subspace of <m>V</m> relative to <m>T</m>.  Then, for any <m>\vect{v}\in V</m> there is a unique decomposition <m>\vect{v}=\vect{u}_1+\vect{u}_2+\vect{u}_3+\cdots+\vect{u}_m</m> with <m>\vect{u}_i\in U_i</m>, <m>1\leq i\leq m</m> and furthermore
<me><md>
<mrow>
\lt{T}{\vect{v}}
</mrow>
<mrow>&amp;=\lt{T}{\vect{u}_1+\vect{u}_2+\vect{u}_3+\cdots+\vect{u}_m}]]>
</mrow>
<mrow>&amp;&]]><acroref type="definition" acro="DS" />
</mrow>
<mrow>&amp;=\lt{T}{\vect{u}_1}+\lt{T}{\vect{u}_2}+\lt{T}{\vect{u}_3}+\cdots+\lt{T}{\vect{u}_m}]]>
</mrow>
<mrow>&amp;&]]><acroref type="theorem" acro="LTLC" />
</mrow>
<mrow>&amp;=\lt{\restrict{T}{U_1}}{\vect{u}_1}+\lt{\restrict{T}{U_2}}{\vect{u}_2}+\lt{\restrict{T}{U_3}}{\vect{u}_3}+\cdots+\lt{\restrict{T}{U_m}}{\vect{u}_m}]]>
</mrow>
</md></me>
So in a very real sense, we obtain a decomposition of the linear transformation <m>T</m> into the restrictions <m>\restrict{T}{U_i}</m>, <m>1\leq i\leq m</m>.  If we wanted to be more careful, we could extend each restriction to a linear transformation defined on <m>V</m> by setting the output of <m>\restrict{T}{U_i}</m> to be the zero vector for inputs outside of <m>U_i</m>.  Then <m>T</m> would be exactly equal to the sum (<acroref type="definition" acro="LTA" />) of these extended restrictions.  However, the irony of extending our restrictions is more than we could handle right now.<p><p>
Our real interest is in the matrix representation of a linear transformation when the domain decomposes as a direct sum of invariant subspaces.  Consider forming a basis <m>B</m> of <m>V</m> as the union of bases <m>B_i</m> from the individual <m>U_i</m>, <ie /> <m>B=\cup_{i=1}^m\,B_i</m>.  Now form the matrix representation of <m>T</m> relative to <m>B</m>.  The result will be block diagonal, where each block is the matrix representation of a restriction <m>\restrict{T}{U_i}</m> relative to a basis <m>B_i</m>, <m>\matrixrep{\restrict{T}{U_i}}{B_i}{B_i}</m>.  Though we did not have the definitions to describe it then, this is exactly what was going on in the latter portion of the proof of  <acroref type="theorem" acro="CFNLT" />.   Two examples should help to clarify these ideas.<p><p>





Invariant subspaces, and restrictions of linear transformations, are topics you will see again and again if you continue with further study of linear algebra.  Our reasons for discussing them now is to arrive at a nice matrix representation of the restriction of a linear transformation to one of its generalized eigenspaces.  Here's the theorem.
<theorem acro="MRRGE" index="matrix representation!restriction to generalized eigenspace">
<title>Matrix Representation of a Restriction to a Generalized Eigenspace</title>
<statement>
Suppose that <m>\ltdefn{T}{V}{V}</m> is a linear transformation with eigenvalue <m>\lambda</m>.  Then there is a basis of the the generalized eigenspace <m>\geneigenspace{T}{\lambda}</m> such that the restriction <m>\ltdefn{\restrict{T}{\geneigenspace{T}{\lambda}}}{\geneigenspace{T}{\lambda}}{\geneigenspace{T}{\lambda}}</m> has a matrix representation that is block diagonal where each block is a Jordan block of the form <m>\jordan{n}{\lambda}</m>.
</statement>

<proof>
<acroref type="theorem" acro="RGEN" /> tells us that <m>\restrict{T}{\geneigenspace{T}{\lambda}}-\lambda I_{\geneigenspace{T}{\lambda}}</m> is a nilpotent linear transformation.  <acroref type="theorem" acro="CFNLT" /> tells us that a nilpotent linear transformation has a basis for its domain that yields a matrix representation that is block diagonal where the blocks are Jordan blocks of the form <m>\jordan{n}{0}</m>.  Let <m>B</m> be a basis of <m>\geneigenspace{T}{\lambda}</m> that yields such a matrix representation for <m>\restrict{T}{\geneigenspace{T}{\lambda}}-\lambda I_{\geneigenspace{T}{\lambda}}</m>.<p><p>
By <acroref type="definition" acro="LTA" />, we can write
<me><md>
<mrow>
\restrict{T}{\geneigenspace{T}{\lambda}}
</mrow>
<mrow>&amp;=\left(]]>
\restrict{T}{\geneigenspace{T}{\lambda}}-\lambda I_{\geneigenspace{T}{\lambda}}
\right)
+\lambda I_{\geneigenspace{T}{\lambda}}
</mrow>
</md></me>
The matrix representation of <m>\lambda I_{\geneigenspace{T}{\lambda}}</m> relative to the basis <m>B</m> is then simply the diagonal matrix <m>\lambda I_m</m>, where <m>m=\dimension{\geneigenspace{T}{\lambda}}</m>.  By <acroref type="theorem" acro="MRSLT" /> we have the rather unwieldy expression,
<me><md>
<mrow>
\matrixrep{\restrict{T}{\geneigenspace{T}{\lambda}}}{B}{B}
</mrow>
<mrow>&amp;=]]>
\matrixrep{\left(
\restrict{T}{\geneigenspace{T}{\lambda}}-\lambda I_{\geneigenspace{T}{\lambda}}
\right)
+\lambda I_{\geneigenspace{T}{\lambda}}}{B}{B}\\
</mrow>
<mrow>&amp;=]]>
\matrixrep{
\restrict{T}{\geneigenspace{T}{\lambda}}-\lambda I_{\geneigenspace{T}{\lambda}}
}{B}{B}
+
\matrixrep{I_{\geneigenspace{T}{\lambda}}}{B}{B}
</mrow>
</md></me>
The first of these matrix representations has Jordan blocks with zero in every diagonal entry, while the second matrix representation has <m>\lambda</m> in every diagonal entry.  The result of adding the two representations is to convert the Jordan blocks from the form <m>\jordan{n}{0}</m> to the form <m>\jordan{n}{\lambda}</m>.
</proof>
</theorem>

Of course, <acroref type="theorem" acro="CFNLT" /> provides some extra information on the sizes of the Jordan blocks in a representation and we could carry over this information to <acroref type="theorem" acro="MRRGE" />, but will save that for a subsequent application of this result.
<!--   End  IS.tex -->
</subsection>
</section>
